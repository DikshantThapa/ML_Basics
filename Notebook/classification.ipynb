{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will be talking and working on the preprocessed data for using and applying classification tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.discrete.discrete_model as snd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/dikshantthapa/PycharmProjects/pythonProject/Data Files/day2/Classification.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Data is already a cleaned data i will try to implement the models to predict wheather it is sold in 3 months or not \n",
    "and i will be checking the accuracy using the confusion matrix and r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[:,data.columns!='Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.19200</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>4.0875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.17280</td>\n",
       "      <td>42</td>\n",
       "      <td>0.046146</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>7.394</td>\n",
       "      <td>46.19856</td>\n",
       "      <td>38</td>\n",
       "      <td>0.045764</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.26720</td>\n",
       "      <td>45</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>6.0650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.28960</td>\n",
       "      <td>55</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>6.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  resid_area  air_qual  room_num   age  teachers  poor_prop  \\\n",
       "0   24.0       32.31     0.538     6.575  65.2      24.7       4.98   \n",
       "1   21.6       37.07     0.469     6.421  78.9      22.2       9.14   \n",
       "2   34.7       37.07     0.469     7.185  61.1      22.2       4.03   \n",
       "3   33.4       32.18     0.458     6.998  45.8      21.3       2.94   \n",
       "4   36.2       32.18     0.458     7.147  54.2      21.3       5.33   \n",
       "\n",
       "   n_hos_beds  n_hot_rooms  rainfall     parks  avg_dist  airport_YES  \\\n",
       "0       5.480     11.19200        23  0.049347    4.0875            1   \n",
       "1       7.332     12.17280        42  0.046146    4.9675            0   \n",
       "2       7.394     46.19856        38  0.045764    4.9675            0   \n",
       "3       9.268     11.26720        45  0.047151    6.0650            1   \n",
       "4       8.824     11.28960        55  0.039474    6.0625            0   \n",
       "\n",
       "   waterbody_Lake  waterbody_Lake and River  waterbody_River  \n",
       "0               0                         0                1  \n",
       "1               1                         0                0  \n",
       "2               0                         0                0  \n",
       "3               1                         0                0  \n",
       "4               1                         0                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= data['Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 16) (152, 16) (354,) (152,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_logistic.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_result = model_multi_logistic.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_result = model_multi_logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.43677545924736916"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,y_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3489384866630376"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_train,y_train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.547436\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "model_multi_stat = snd.Logit(Y_train,X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_stats = model_multi_stat.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_stats = model_multi_stat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Sold</td>       <th>  No. Observations:  </th>  <td>   354</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   338</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 25 Apr 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.2084</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:48:10</td>     <th>  Log-Likelihood:    </th> <td> -193.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -244.81</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.366e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th>                    <td>   -0.2936</td> <td>    0.042</td> <td>   -7.058</td> <td> 0.000</td> <td>   -0.375</td> <td>   -0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resid_area</th>               <td>   -0.0069</td> <td>    0.028</td> <td>   -0.251</td> <td> 0.802</td> <td>   -0.061</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>air_qual</th>                 <td>   -9.3536</td> <td>    3.280</td> <td>   -2.851</td> <td> 0.004</td> <td>  -15.783</td> <td>   -2.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_num</th>                 <td>    1.2731</td> <td>    0.295</td> <td>    4.319</td> <td> 0.000</td> <td>    0.695</td> <td>    1.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                      <td>   -0.0074</td> <td>    0.008</td> <td>   -0.870</td> <td> 0.384</td> <td>   -0.024</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teachers</th>                 <td>    0.2725</td> <td>    0.069</td> <td>    3.955</td> <td> 0.000</td> <td>    0.137</td> <td>    0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>poor_prop</th>                <td>   -0.1936</td> <td>    0.040</td> <td>   -4.831</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_hos_beds</th>               <td>    0.2765</td> <td>    0.086</td> <td>    3.224</td> <td> 0.001</td> <td>    0.108</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_hot_rooms</th>              <td>   -0.0670</td> <td>    0.052</td> <td>   -1.295</td> <td> 0.195</td> <td>   -0.168</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rainfall</th>                 <td>   -0.0087</td> <td>    0.010</td> <td>   -0.854</td> <td> 0.393</td> <td>   -0.029</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parks</th>                    <td>   38.3610</td> <td>   29.731</td> <td>    1.290</td> <td> 0.197</td> <td>  -19.910</td> <td>   96.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_dist</th>                 <td>   -0.5808</td> <td>    0.120</td> <td>   -4.832</td> <td> 0.000</td> <td>   -0.816</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>airport_YES</th>              <td>   -0.2237</td> <td>    0.258</td> <td>   -0.867</td> <td> 0.386</td> <td>   -0.730</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_Lake</th>           <td>   -0.0177</td> <td>    0.369</td> <td>   -0.048</td> <td> 0.962</td> <td>   -0.742</td> <td>    0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_Lake and River</th> <td>    0.1447</td> <td>    0.408</td> <td>    0.355</td> <td> 0.723</td> <td>   -0.655</td> <td>    0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterbody_River</th>          <td>    0.4856</td> <td>    0.313</td> <td>    1.550</td> <td> 0.121</td> <td>   -0.128</td> <td>    1.100</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   Sold   No. Observations:                  354\n",
       "Model:                          Logit   Df Residuals:                      338\n",
       "Method:                           MLE   Df Model:                           15\n",
       "Date:                Tue, 25 Apr 2023   Pseudo R-squ.:                  0.2084\n",
       "Time:                        23:48:10   Log-Likelihood:                -193.79\n",
       "converged:                       True   LL-Null:                       -244.81\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.366e-15\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "price                       -0.2936      0.042     -7.058      0.000      -0.375      -0.212\n",
       "resid_area                  -0.0069      0.028     -0.251      0.802      -0.061       0.047\n",
       "air_qual                    -9.3536      3.280     -2.851      0.004     -15.783      -2.924\n",
       "room_num                     1.2731      0.295      4.319      0.000       0.695       1.851\n",
       "age                         -0.0074      0.008     -0.870      0.384      -0.024       0.009\n",
       "teachers                     0.2725      0.069      3.955      0.000       0.137       0.407\n",
       "poor_prop                   -0.1936      0.040     -4.831      0.000      -0.272      -0.115\n",
       "n_hos_beds                   0.2765      0.086      3.224      0.001       0.108       0.445\n",
       "n_hot_rooms                 -0.0670      0.052     -1.295      0.195      -0.168       0.034\n",
       "rainfall                    -0.0087      0.010     -0.854      0.393      -0.029       0.011\n",
       "parks                       38.3610     29.731      1.290      0.197     -19.910      96.632\n",
       "avg_dist                    -0.5808      0.120     -4.832      0.000      -0.816      -0.345\n",
       "airport_YES                 -0.2237      0.258     -0.867      0.386      -0.730       0.282\n",
       "waterbody_Lake              -0.0177      0.369     -0.048      0.962      -0.742       0.706\n",
       "waterbody_Lake and River     0.1447      0.408      0.355      0.723      -0.655       0.944\n",
       "waterbody_River              0.4856      0.313      1.550      0.121      -0.128       1.100\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_stat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9701716 , 0.0298284 ],\n",
       "       [0.26160088, 0.73839912],\n",
       "       [0.5107375 , 0.4892625 ],\n",
       "       [0.21839366, 0.78160634],\n",
       "       [0.74957976, 0.25042024],\n",
       "       [0.72858441, 0.27141559],\n",
       "       [0.50282803, 0.49717197],\n",
       "       [0.77052025, 0.22947975],\n",
       "       [0.30171002, 0.69828998],\n",
       "       [0.55054049, 0.44945951],\n",
       "       [0.68192346, 0.31807654],\n",
       "       [0.4487221 , 0.5512779 ],\n",
       "       [0.94022373, 0.05977627],\n",
       "       [0.64926386, 0.35073614],\n",
       "       [0.28444713, 0.71555287],\n",
       "       [0.69042797, 0.30957203],\n",
       "       [0.42221578, 0.57778422],\n",
       "       [0.36105034, 0.63894966],\n",
       "       [0.32318279, 0.67681721],\n",
       "       [0.73229057, 0.26770943],\n",
       "       [0.2680763 , 0.7319237 ],\n",
       "       [0.25038136, 0.74961864],\n",
       "       [0.64896027, 0.35103973],\n",
       "       [0.2252281 , 0.7747719 ],\n",
       "       [0.382299  , 0.617701  ],\n",
       "       [0.81923834, 0.18076166],\n",
       "       [0.85541212, 0.14458788],\n",
       "       [0.5763227 , 0.4236773 ],\n",
       "       [0.44476216, 0.55523784],\n",
       "       [0.09869216, 0.90130784],\n",
       "       [0.31466902, 0.68533098],\n",
       "       [0.5760928 , 0.4239072 ],\n",
       "       [0.61081881, 0.38918119],\n",
       "       [0.39991443, 0.60008557],\n",
       "       [0.86158838, 0.13841162],\n",
       "       [0.67733527, 0.32266473],\n",
       "       [0.9814576 , 0.0185424 ],\n",
       "       [0.31508042, 0.68491958],\n",
       "       [0.48338169, 0.51661831],\n",
       "       [0.56968708, 0.43031292],\n",
       "       [0.33585299, 0.66414701],\n",
       "       [0.34447694, 0.65552306],\n",
       "       [0.66595484, 0.33404516],\n",
       "       [0.22101518, 0.77898482],\n",
       "       [0.10633459, 0.89366541],\n",
       "       [0.47749111, 0.52250889],\n",
       "       [0.14345027, 0.85654973],\n",
       "       [0.89902127, 0.10097873],\n",
       "       [0.33436012, 0.66563988],\n",
       "       [0.55943895, 0.44056105],\n",
       "       [0.82324195, 0.17675805],\n",
       "       [0.61558014, 0.38441986],\n",
       "       [0.48490978, 0.51509022],\n",
       "       [0.15459369, 0.84540631],\n",
       "       [0.42420988, 0.57579012],\n",
       "       [0.60044817, 0.39955183],\n",
       "       [0.44187186, 0.55812814],\n",
       "       [0.3229946 , 0.6770054 ],\n",
       "       [0.26294678, 0.73705322],\n",
       "       [0.38854982, 0.61145018],\n",
       "       [0.14820093, 0.85179907],\n",
       "       [0.30702828, 0.69297172],\n",
       "       [0.45011522, 0.54988478],\n",
       "       [0.29620215, 0.70379785],\n",
       "       [0.75357581, 0.24642419],\n",
       "       [0.45452411, 0.54547589],\n",
       "       [0.14357616, 0.85642384],\n",
       "       [0.96047299, 0.03952701],\n",
       "       [0.83612335, 0.16387665],\n",
       "       [0.90511026, 0.09488974],\n",
       "       [0.79688334, 0.20311666],\n",
       "       [0.29153585, 0.70846415],\n",
       "       [0.70077722, 0.29922278],\n",
       "       [0.72644474, 0.27355526],\n",
       "       [0.64196505, 0.35803495],\n",
       "       [0.17647136, 0.82352864],\n",
       "       [0.33533158, 0.66466842],\n",
       "       [0.58401129, 0.41598871],\n",
       "       [0.37715437, 0.62284563],\n",
       "       [0.24725452, 0.75274548],\n",
       "       [0.40420054, 0.59579946],\n",
       "       [0.70292819, 0.29707181],\n",
       "       [0.40029804, 0.59970196],\n",
       "       [0.37812368, 0.62187632],\n",
       "       [0.57217336, 0.42782664],\n",
       "       [0.56667371, 0.43332629],\n",
       "       [0.44830133, 0.55169867],\n",
       "       [0.43299262, 0.56700738],\n",
       "       [0.00975164, 0.99024836],\n",
       "       [0.59995003, 0.40004997],\n",
       "       [0.32758941, 0.67241059],\n",
       "       [0.33815071, 0.66184929],\n",
       "       [0.76163767, 0.23836233],\n",
       "       [0.8258283 , 0.1741717 ],\n",
       "       [0.94306698, 0.05693302],\n",
       "       [0.8953092 , 0.1046908 ],\n",
       "       [0.72084527, 0.27915473],\n",
       "       [0.46098327, 0.53901673],\n",
       "       [0.9935346 , 0.0064654 ],\n",
       "       [0.35900158, 0.64099842],\n",
       "       [0.30196518, 0.69803482],\n",
       "       [0.64551332, 0.35448668],\n",
       "       [0.55602813, 0.44397187],\n",
       "       [0.55189787, 0.44810213],\n",
       "       [0.52034461, 0.47965539],\n",
       "       [0.32588206, 0.67411794],\n",
       "       [0.78300778, 0.21699222],\n",
       "       [0.81931777, 0.18068223],\n",
       "       [0.28274746, 0.71725254],\n",
       "       [0.60529276, 0.39470724],\n",
       "       [0.74635393, 0.25364607],\n",
       "       [0.60744267, 0.39255733],\n",
       "       [0.13578485, 0.86421515],\n",
       "       [0.61908673, 0.38091327],\n",
       "       [0.3865863 , 0.6134137 ],\n",
       "       [0.95506942, 0.04493058],\n",
       "       [0.64103803, 0.35896197],\n",
       "       [0.33221596, 0.66778404],\n",
       "       [0.53478512, 0.46521488],\n",
       "       [0.52458337, 0.47541663],\n",
       "       [0.72122287, 0.27877713],\n",
       "       [0.55542706, 0.44457294],\n",
       "       [0.23624835, 0.76375165],\n",
       "       [0.43809715, 0.56190285],\n",
       "       [0.48054045, 0.51945955],\n",
       "       [0.5067559 , 0.4932441 ],\n",
       "       [0.72998915, 0.27001085],\n",
       "       [0.42039369, 0.57960631],\n",
       "       [0.79395778, 0.20604222],\n",
       "       [0.69381005, 0.30618995],\n",
       "       [0.7185771 , 0.2814229 ],\n",
       "       [0.56115225, 0.43884775],\n",
       "       [0.67525718, 0.32474282],\n",
       "       [0.32479494, 0.67520506],\n",
       "       [0.98819202, 0.01180798],\n",
       "       [0.92124294, 0.07875706],\n",
       "       [0.31382101, 0.68617899],\n",
       "       [0.20795817, 0.79204183],\n",
       "       [0.52011699, 0.47988301],\n",
       "       [0.62568659, 0.37431341],\n",
       "       [0.69257666, 0.30742334],\n",
       "       [0.40185266, 0.59814734],\n",
       "       [0.57613805, 0.42386195],\n",
       "       [0.32353044, 0.67646956],\n",
       "       [0.93840957, 0.06159043],\n",
       "       [0.59154684, 0.40845316],\n",
       "       [0.43054038, 0.56945962],\n",
       "       [0.62584635, 0.37415365],\n",
       "       [0.20030276, 0.79969724],\n",
       "       [0.4584023 , 0.5415977 ],\n",
       "       [0.49748531, 0.50251469],\n",
       "       [0.6429827 , 0.3570173 ],\n",
       "       [0.60185795, 0.39814205],\n",
       "       [0.67414129, 0.32585871],\n",
       "       [0.49698527, 0.50301473],\n",
       "       [0.95787435, 0.04212565],\n",
       "       [0.48961769, 0.51038231],\n",
       "       [0.86604011, 0.13395989],\n",
       "       [0.8988055 , 0.1011945 ],\n",
       "       [0.4796736 , 0.5203264 ],\n",
       "       [0.30776628, 0.69223372],\n",
       "       [0.50764556, 0.49235444],\n",
       "       [0.55186496, 0.44813504],\n",
       "       [0.36890191, 0.63109809],\n",
       "       [0.34333798, 0.65666202],\n",
       "       [0.62715661, 0.37284339],\n",
       "       [0.36764262, 0.63235738],\n",
       "       [0.46636919, 0.53363081],\n",
       "       [0.82110903, 0.17889097],\n",
       "       [0.58457782, 0.41542218],\n",
       "       [0.19662514, 0.80337486],\n",
       "       [0.41142601, 0.58857399],\n",
       "       [0.70395157, 0.29604843],\n",
       "       [0.50539434, 0.49460566],\n",
       "       [0.19948118, 0.80051882],\n",
       "       [0.1580152 , 0.8419848 ],\n",
       "       [0.77992478, 0.22007522],\n",
       "       [0.30284217, 0.69715783],\n",
       "       [0.23319749, 0.76680251],\n",
       "       [0.36213062, 0.63786938],\n",
       "       [0.15934104, 0.84065896],\n",
       "       [0.36769992, 0.63230008],\n",
       "       [0.35362299, 0.64637701],\n",
       "       [0.65486591, 0.34513409],\n",
       "       [0.14134662, 0.85865338],\n",
       "       [0.66430238, 0.33569762],\n",
       "       [0.97106107, 0.02893893],\n",
       "       [0.69261541, 0.30738459],\n",
       "       [0.91680744, 0.08319256],\n",
       "       [0.74639027, 0.25360973],\n",
       "       [0.48483397, 0.51516603],\n",
       "       [0.73477911, 0.26522089],\n",
       "       [0.03514719, 0.96485281],\n",
       "       [0.58602896, 0.41397104],\n",
       "       [0.27537634, 0.72462366],\n",
       "       [0.38363865, 0.61636135],\n",
       "       [0.36733419, 0.63266581],\n",
       "       [0.70194308, 0.29805692],\n",
       "       [0.32537925, 0.67462075],\n",
       "       [0.70763188, 0.29236812],\n",
       "       [0.25223206, 0.74776794],\n",
       "       [0.51148109, 0.48851891],\n",
       "       [0.39912851, 0.60087149],\n",
       "       [0.05835107, 0.94164893],\n",
       "       [0.67201951, 0.32798049],\n",
       "       [0.55439642, 0.44560358],\n",
       "       [0.46222009, 0.53777991],\n",
       "       [0.67659235, 0.32340765],\n",
       "       [0.67129385, 0.32870615],\n",
       "       [0.27314069, 0.72685931],\n",
       "       [0.70834866, 0.29165134],\n",
       "       [0.49533501, 0.50466499],\n",
       "       [0.96576221, 0.03423779],\n",
       "       [0.36441779, 0.63558221],\n",
       "       [0.12071754, 0.87928246],\n",
       "       [0.2153239 , 0.7846761 ],\n",
       "       [0.86311721, 0.13688279],\n",
       "       [0.39772987, 0.60227013],\n",
       "       [0.75643422, 0.24356578],\n",
       "       [0.1713751 , 0.8286249 ],\n",
       "       [0.35353212, 0.64646788],\n",
       "       [0.35235889, 0.64764111],\n",
       "       [0.7699265 , 0.2300735 ],\n",
       "       [0.60196742, 0.39803258],\n",
       "       [0.13923219, 0.86076781],\n",
       "       [0.1410172 , 0.8589828 ],\n",
       "       [0.29762529, 0.70237471],\n",
       "       [0.99733172, 0.00266828],\n",
       "       [0.12766759, 0.87233241],\n",
       "       [0.57254463, 0.42745537],\n",
       "       [0.82277987, 0.17722013],\n",
       "       [0.74265457, 0.25734543],\n",
       "       [0.54905745, 0.45094255],\n",
       "       [0.47336788, 0.52663212],\n",
       "       [0.9958758 , 0.0041242 ],\n",
       "       [0.9336531 , 0.0663469 ],\n",
       "       [0.57684506, 0.42315494],\n",
       "       [0.53519227, 0.46480773],\n",
       "       [0.24018399, 0.75981601],\n",
       "       [0.84096788, 0.15903212],\n",
       "       [0.40464818, 0.59535182],\n",
       "       [0.57960418, 0.42039582],\n",
       "       [0.6035278 , 0.3964722 ],\n",
       "       [0.97888158, 0.02111842],\n",
       "       [0.81835358, 0.18164642],\n",
       "       [0.98560197, 0.01439803],\n",
       "       [0.13547474, 0.86452526],\n",
       "       [0.88651665, 0.11348335],\n",
       "       [0.40669755, 0.59330245],\n",
       "       [0.45529199, 0.54470801],\n",
       "       [0.86619038, 0.13380962],\n",
       "       [0.75040706, 0.24959294],\n",
       "       [0.51492407, 0.48507593],\n",
       "       [0.83780599, 0.16219401],\n",
       "       [0.72461636, 0.27538364],\n",
       "       [0.50453556, 0.49546444],\n",
       "       [0.36659853, 0.63340147],\n",
       "       [0.25349303, 0.74650697],\n",
       "       [0.70240661, 0.29759339],\n",
       "       [0.36115549, 0.63884451],\n",
       "       [0.89566772, 0.10433228],\n",
       "       [0.56265395, 0.43734605],\n",
       "       [0.44277313, 0.55722687],\n",
       "       [0.75931503, 0.24068497],\n",
       "       [0.41444106, 0.58555894],\n",
       "       [0.63168192, 0.36831808],\n",
       "       [0.17250723, 0.82749277],\n",
       "       [0.90647197, 0.09352803],\n",
       "       [0.10694356, 0.89305644],\n",
       "       [0.40244864, 0.59755136],\n",
       "       [0.92808693, 0.07191307],\n",
       "       [0.15493644, 0.84506356],\n",
       "       [0.75676079, 0.24323921],\n",
       "       [0.78023688, 0.21976312],\n",
       "       [0.83157551, 0.16842449],\n",
       "       [0.64299086, 0.35700914],\n",
       "       [0.45520462, 0.54479538],\n",
       "       [0.72952746, 0.27047254],\n",
       "       [0.30349172, 0.69650828],\n",
       "       [0.50564352, 0.49435648],\n",
       "       [0.39282882, 0.60717118],\n",
       "       [0.73812563, 0.26187437],\n",
       "       [0.9131302 , 0.0868698 ],\n",
       "       [0.74535662, 0.25464338],\n",
       "       [0.71266385, 0.28733615],\n",
       "       [0.22473929, 0.77526071],\n",
       "       [0.3458448 , 0.6541552 ],\n",
       "       [0.64882251, 0.35117749],\n",
       "       [0.36445061, 0.63554939],\n",
       "       [0.48313668, 0.51686332],\n",
       "       [0.36853413, 0.63146587],\n",
       "       [0.48300106, 0.51699894],\n",
       "       [0.30860201, 0.69139799],\n",
       "       [0.59292448, 0.40707552],\n",
       "       [0.8020578 , 0.1979422 ],\n",
       "       [0.98159674, 0.01840326],\n",
       "       [0.91350846, 0.08649154],\n",
       "       [0.40001496, 0.59998504],\n",
       "       [0.88385607, 0.11614393],\n",
       "       [0.65871907, 0.34128093],\n",
       "       [0.24802801, 0.75197199],\n",
       "       [0.7394001 , 0.2605999 ],\n",
       "       [0.77578638, 0.22421362],\n",
       "       [0.85611594, 0.14388406],\n",
       "       [0.51636378, 0.48363622],\n",
       "       [0.2868945 , 0.7131055 ],\n",
       "       [0.47086271, 0.52913729],\n",
       "       [0.89899519, 0.10100481],\n",
       "       [0.41149994, 0.58850006],\n",
       "       [0.54269768, 0.45730232],\n",
       "       [0.86657638, 0.13342362],\n",
       "       [0.26438164, 0.73561836],\n",
       "       [0.75476659, 0.24523341],\n",
       "       [0.32012042, 0.67987958],\n",
       "       [0.48222937, 0.51777063],\n",
       "       [0.27544061, 0.72455939],\n",
       "       [0.38199096, 0.61800904],\n",
       "       [0.38979567, 0.61020433],\n",
       "       [0.52796318, 0.47203682],\n",
       "       [0.62978011, 0.37021989],\n",
       "       [0.2767178 , 0.7232822 ],\n",
       "       [0.60461555, 0.39538445],\n",
       "       [0.37223084, 0.62776916],\n",
       "       [0.53160335, 0.46839665],\n",
       "       [0.27335414, 0.72664586],\n",
       "       [0.28935138, 0.71064862],\n",
       "       [0.31850553, 0.68149447],\n",
       "       [0.41974801, 0.58025199],\n",
       "       [0.20432164, 0.79567836],\n",
       "       [0.35956031, 0.64043969],\n",
       "       [0.31659979, 0.68340021],\n",
       "       [0.16854269, 0.83145731],\n",
       "       [0.53628049, 0.46371951],\n",
       "       [0.60264238, 0.39735762],\n",
       "       [0.44610078, 0.55389922],\n",
       "       [0.4284438 , 0.5715562 ],\n",
       "       [0.27091643, 0.72908357],\n",
       "       [0.08721975, 0.91278025],\n",
       "       [0.70919663, 0.29080337],\n",
       "       [0.22256169, 0.77743831],\n",
       "       [0.37734223, 0.62265777],\n",
       "       [0.29732675, 0.70267325],\n",
       "       [0.65306702, 0.34693298],\n",
       "       [0.55294825, 0.44705175],\n",
       "       [0.95312213, 0.04687787],\n",
       "       [0.64992467, 0.35007533],\n",
       "       [0.66963787, 0.33036213],\n",
       "       [0.92810251, 0.07189749],\n",
       "       [0.33015236, 0.66984764],\n",
       "       [0.66939348, 0.33060652],\n",
       "       [0.53824386, 0.46175614],\n",
       "       [0.15214123, 0.84785877],\n",
       "       [0.81259256, 0.18740744],\n",
       "       [0.46099309, 0.53900691]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi_logistic.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pp = model_multi_logistic.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ppp = (model_multi_logistic.predict_proba(X_train)[:,1]>= 0.3).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  61],\n",
       "       [ 58, 109]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_train,y_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lda = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lda1 = lda.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4638844301765648"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,y_pred_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25825354638316944"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_train,y_pred_lda1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_a = lda.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[188,  88],\n",
       "       [ 77, 153]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,Y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
